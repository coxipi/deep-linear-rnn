defaults:
  - hydra: default
  - _self_

save_dir: "logs/"
seed: 1

logger:
  _target_: lightning.pytorch.loggers.WandbLogger
  entity: guillaume-rabusseau 
  project: deep-linear-rnn 
  name: ${now:%Y-%m-%d}_${now:%H-%M-%S}
  save_dir: ${save_dir}
  offline: False
  tags: null

train_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 1000
  seq_len: 10
  vocab_size: 2 
  lookahead: 6
  datatype: "int"

val_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 200
  seq_len: 10
  vocab_size: 2 
  lookahead: 6
  datatype: "int"

test_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 200
  seq_len: 10
  vocab_size: 2 
  lookahead: 6
  datatype: "int"

datamodule:
  _target_: dataset.SyntheticCopyDataModule
  batch_size: 32 
  train_dataset: ${train_dataset}
  val_dataset: ${val_dataset}
  test_dataset: ${test_dataset}

trainer:
  max_epochs: 500
  enable_progress_bar: True
  log_every_n_steps: 10
  limit_train_batches: 0.1
  accelerator: "cpu"

model:
  _target_: model.DeepRNNWithEmbedding
  vocab_size: ${train_dataset.vocab_size}
  embedding_dim: 32
  hidden_size: 64 
  output_size: ${train_dataset.vocab_size}
  num_layers: 4
  activation: 'relu'
  readout_activation: 'identity'

callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_loss
    patience: 1000
    mode: min
    verbose: True
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: val_loss
    mode: min
    save_top_k: 1
    filename: "{epoch:02d}-{val_loss:.2f}"
    dirpath: ${save_dir}
    verbose: True

task :
  _target_: task.CopyTaskTokenized
  model: ${model}
  lr: 1e-3
