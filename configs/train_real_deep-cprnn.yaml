defaults:
  - hydra: default
  - _self_

save_dir: "logs/"
seed: 8

logger:
  _target_: lightning.pytorch.loggers.WandbLogger
  entity: guillaume-rabusseau 
  project: deep-linear-rnn 
  name: ${now:%Y-%m-%d}_${now:%H-%M-%S}
  save_dir: ${save_dir}
  offline: False
  tags: null

train_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 1000
  seq_len: 12
  vocab_size: 2 
  lookahead: 6
  datatype: "real"
  copymode: "linear"

val_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 200
  seq_len: 12
  vocab_size: 2 
  lookahead: 6
  datatype: "real"
  copymode: "linear"

test_dataset:
  _target_: dataset.SyntheticCopyDataset
  n_samples: 200
  seq_len: 12
  vocab_size: 2 
  lookahead: 6
  datatype: "real"
  copymode: "linear"

datamodule:
  _target_: dataset.SyntheticCopyDataModule
  batch_size: 15
  train_dataset: ${train_dataset}
  val_dataset: ${val_dataset}
  test_dataset: ${test_dataset}

trainer:
  max_epochs: 1000
  enable_progress_bar: True
  log_every_n_steps: 1
  limit_train_batches: 1.0
  accelerator: "auto"

model:
  _target_: cprnn.DeepCPRNN
  vocab_size: ${train_dataset.vocab_size}
  hidden_size: 64 
  num_layers: 4
  embedding_dim: null
  rank: 8
  tokenizer: None
  dropout: 0.1
  dropout_between_layers: False
  activation: 'identity'
  readout_activation: 'identity'
  gate: 'identity'


callbacks:
  early_stopping:
    _target_: lightning.pytorch.callbacks.EarlyStopping
    monitor: val_loss
    patience: 1000
    mode: min
    verbose: True
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    monitor: val_loss
    mode: min
    save_top_k: 1
    filename: "{epoch:02d}-{val_loss:.2f}"
    dirpath: ${save_dir}
    verbose: True

task :
  _target_: task.CopyTaskRegression
  model: ${model}
  lr: 1e-3
